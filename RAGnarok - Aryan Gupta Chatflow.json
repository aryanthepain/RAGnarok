{
  "nodes": [
    {
      "id": "conversationalRetrievalQAChain_0",
      "position": {
        "x": 1102.430954468476,
        "y": 213.29004017043286
      },
      "type": "customNode",
      "data": {
        "id": "conversationalRetrievalQAChain_0",
        "label": "Conversational Retrieval QA Chain",
        "version": 3,
        "name": "conversationalRetrievalQAChain",
        "type": "ConversationalRetrievalQAChain",
        "baseClasses": [
          "ConversationalRetrievalQAChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Document QA - built on RetrievalQAChain to provide a chat history component",
        "inputParams": [
          {
            "label": "Return Source Documents",
            "name": "returnSourceDocuments",
            "type": "boolean",
            "optional": true,
            "id": "conversationalRetrievalQAChain_0-input-returnSourceDocuments-boolean"
          },
          {
            "label": "Rephrase Prompt",
            "name": "rephrasePrompt",
            "type": "string",
            "description": "Using previous chat history, rephrase question into a standalone question",
            "warning": "Prompt must include input variables: {chat_history} and {question}",
            "rows": 4,
            "additionalParams": true,
            "optional": true,
            "default": "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone Question:",
            "id": "conversationalRetrievalQAChain_0-input-rephrasePrompt-string"
          },
          {
            "label": "Response Prompt",
            "name": "responsePrompt",
            "type": "string",
            "description": "Taking the rephrased question, search for answer from the provided context",
            "warning": "Prompt must include input variable: {context}",
            "rows": 4,
            "additionalParams": true,
            "optional": true,
            "default": "I want you to act as a document that I am having a conversation with. Your name is \"AI Assistant\". Using the provided context, answer the user's question to the best of your ability using the resources provided.\nIf there is nothing in the context relevant to the question at hand, just say \"Hmm, I'm not sure\" and stop after that. Refuse to answer any question not about the info. Never break character.\n------------\n{context}\n------------\nREMEMBER: If there is no relevant information within the context, just say \"Hmm, I'm not sure\". Don't try to make up an answer. Never break character.",
            "id": "conversationalRetrievalQAChain_0-input-responsePrompt-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "id": "conversationalRetrievalQAChain_0-input-model-BaseChatModel"
          },
          {
            "label": "Vector Store Retriever",
            "name": "vectorStoreRetriever",
            "type": "BaseRetriever",
            "id": "conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseMemory",
            "optional": true,
            "description": "If left empty, a default BufferMemory will be used",
            "id": "conversationalRetrievalQAChain_0-input-memory-BaseMemory"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "conversationalRetrievalQAChain_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "model": "{{chatGoogleGenerativeAI_0.data.instance}}",
          "vectorStoreRetriever": "{{faiss_0.data.instance}}",
          "memory": "{{bufferMemory_0.data.instance}}",
          "returnSourceDocuments": "",
          "rephrasePrompt": "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone Question:",
          "responsePrompt": "I want you to act as a document that I am having a conversation with. Your name is \"AI Assistant\". Using the provided context, answer the user's question to the best of your ability using the resources provided.\nIf there is nothing in the context relevant to the question at hand, just say \"Hmm, I'm not sure\" and stop after that. Refuse to answer any question not about the info. Never break character.\n------------\n{context}\n------------\nREMEMBER: If there is no relevant information within the context, just say \"Hmm, I'm not sure\". Don't try to make up an answer. Never break character.",
          "inputModeration": ""
        },
        "outputAnchors": [
          {
            "id": "conversationalRetrievalQAChain_0-output-conversationalRetrievalQAChain-ConversationalRetrievalQAChain|BaseChain|Runnable",
            "name": "conversationalRetrievalQAChain",
            "label": "ConversationalRetrievalQAChain",
            "description": "Document QA - built on RetrievalQAChain to provide a chat history component",
            "type": "ConversationalRetrievalQAChain | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 530,
      "positionAbsolute": {
        "x": 1102.430954468476,
        "y": 213.29004017043286
      },
      "selected": false
    },
    {
      "id": "bufferMemory_0",
      "position": {
        "x": 755.2202975266082,
        "y": 889.7555938797265
      },
      "type": "customNode",
      "data": {
        "id": "bufferMemory_0",
        "label": "Buffer Memory",
        "version": 2,
        "name": "bufferMemory",
        "type": "BufferMemory",
        "baseClasses": [
          "BufferMemory",
          "BaseChatMemory",
          "BaseMemory"
        ],
        "category": "Memory",
        "description": "Retrieve chat messages stored in database",
        "inputParams": [
          {
            "label": "Session Id",
            "name": "sessionId",
            "type": "string",
            "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.com/memory#ui-and-embedded-chat\">more</a>",
            "default": "",
            "additionalParams": true,
            "optional": true,
            "id": "bufferMemory_0-input-sessionId-string"
          },
          {
            "label": "Memory Key",
            "name": "memoryKey",
            "type": "string",
            "default": "chat_history",
            "additionalParams": true,
            "id": "bufferMemory_0-input-memoryKey-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "sessionId": "",
          "memoryKey": "chat_history"
        },
        "outputAnchors": [
          {
            "id": "bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
            "name": "bufferMemory",
            "label": "BufferMemory",
            "description": "Retrieve chat messages stored in database",
            "type": "BufferMemory | BaseChatMemory | BaseMemory"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 251,
      "selected": false,
      "positionAbsolute": {
        "x": 755.2202975266082,
        "y": 889.7555938797265
      },
      "dragging": false
    },
    {
      "id": "csvFile_0",
      "position": {
        "x": 183.00338625280438,
        "y": 149.5272519337937
      },
      "type": "customNode",
      "data": {
        "id": "csvFile_0",
        "label": "Csv File",
        "version": 1,
        "name": "csvFile",
        "type": "Document",
        "baseClasses": [
          "Document"
        ],
        "category": "Document Loaders",
        "description": "Load data from CSV files",
        "inputParams": [
          {
            "label": "Csv File",
            "name": "csvFile",
            "type": "file",
            "fileType": ".csv",
            "id": "csvFile_0-input-csvFile-file"
          },
          {
            "label": "Single Column Extraction",
            "name": "columnName",
            "type": "string",
            "description": "Extracting a single column",
            "placeholder": "Enter column name",
            "optional": true,
            "id": "csvFile_0-input-columnName-string"
          },
          {
            "label": "Metadata",
            "name": "metadata",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "csvFile_0-input-metadata-json"
          }
        ],
        "inputAnchors": [
          {
            "label": "Text Splitter",
            "name": "textSplitter",
            "type": "TextSplitter",
            "optional": true,
            "id": "csvFile_0-input-textSplitter-TextSplitter"
          }
        ],
        "inputs": {
          "textSplitter": "{{recursiveCharacterTextSplitter_0.data.instance}}",
          "columnName": "",
          "metadata": ""
        },
        "outputAnchors": [
          {
            "id": "csvFile_0-output-csvFile-Document",
            "name": "csvFile",
            "label": "Document",
            "description": "Load data from CSV files",
            "type": "Document"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 510,
      "selected": false,
      "positionAbsolute": {
        "x": 183.00338625280438,
        "y": 149.5272519337937
      },
      "dragging": false
    },
    {
      "id": "recursiveCharacterTextSplitter_0",
      "position": {
        "x": -245.0306888430644,
        "y": 320.4451835660324
      },
      "type": "customNode",
      "data": {
        "id": "recursiveCharacterTextSplitter_0",
        "label": "Recursive Character Text Splitter",
        "version": 2,
        "name": "recursiveCharacterTextSplitter",
        "type": "RecursiveCharacterTextSplitter",
        "baseClasses": [
          "RecursiveCharacterTextSplitter",
          "TextSplitter",
          "BaseDocumentTransformer",
          "Runnable"
        ],
        "category": "Text Splitters",
        "description": "Split documents recursively by different characters - starting with \"\\n\\n\", then \"\\n\", then \" \"",
        "inputParams": [
          {
            "label": "Chunk Size",
            "name": "chunkSize",
            "type": "number",
            "default": 1000,
            "optional": true,
            "id": "recursiveCharacterTextSplitter_0-input-chunkSize-number"
          },
          {
            "label": "Chunk Overlap",
            "name": "chunkOverlap",
            "type": "number",
            "optional": true,
            "id": "recursiveCharacterTextSplitter_0-input-chunkOverlap-number"
          },
          {
            "label": "Custom Separators",
            "name": "separators",
            "type": "string",
            "rows": 4,
            "description": "Array of custom separators to determine when to split the text, will override the default separators",
            "placeholder": "[\"|\", \"##\", \">\", \"-\"]",
            "additionalParams": true,
            "optional": true,
            "id": "recursiveCharacterTextSplitter_0-input-separators-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "chunkSize": 1000,
          "chunkOverlap": "200",
          "separators": ""
        },
        "outputAnchors": [
          {
            "id": "recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
            "name": "recursiveCharacterTextSplitter",
            "label": "RecursiveCharacterTextSplitter",
            "description": "Split documents recursively by different characters - starting with \"\\n\\n\", then \"\\n\", then \" \"",
            "type": "RecursiveCharacterTextSplitter | TextSplitter | BaseDocumentTransformer | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 429,
      "selected": false,
      "positionAbsolute": {
        "x": -245.0306888430644,
        "y": 320.4451835660324
      },
      "dragging": false
    },
    {
      "id": "chatGoogleGenerativeAI_0",
      "position": {
        "x": 696.2020670661773,
        "y": -231.09864382826458
      },
      "type": "customNode",
      "data": {
        "id": "chatGoogleGenerativeAI_0",
        "label": "ChatGoogleGenerativeAI",
        "version": 2,
        "name": "chatGoogleGenerativeAI",
        "type": "ChatGoogleGenerativeAI",
        "baseClasses": [
          "ChatGoogleGenerativeAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "googleGenerativeAI"
            ],
            "optional": false,
            "description": "Google Generative AI credential.",
            "id": "chatGoogleGenerativeAI_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gemini-pro",
            "id": "chatGoogleGenerativeAI_0-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-temperature-number"
          },
          {
            "label": "Max Output Tokens",
            "name": "maxOutputTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-maxOutputTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-topP-number"
          },
          {
            "label": "Top Next Highest Probability Tokens",
            "name": "topK",
            "type": "number",
            "description": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-topK-number"
          },
          {
            "label": "Harm Category",
            "name": "harmCategory",
            "type": "multiOptions",
            "description": "Refer to <a target=\"_blank\" href=\"https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/configure-safety-attributes#safety_attribute_definitions\">official guide</a> on how to use Harm Category",
            "options": [
              {
                "label": "Dangerous",
                "name": "HARM_CATEGORY_DANGEROUS_CONTENT"
              },
              {
                "label": "Harassment",
                "name": "HARM_CATEGORY_HARASSMENT"
              },
              {
                "label": "Hate Speech",
                "name": "HARM_CATEGORY_HATE_SPEECH"
              },
              {
                "label": "Sexually Explicit",
                "name": "HARM_CATEGORY_SEXUALLY_EXPLICIT"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-harmCategory-multiOptions"
          },
          {
            "label": "Harm Block Threshold",
            "name": "harmBlockThreshold",
            "type": "multiOptions",
            "description": "Refer to <a target=\"_blank\" href=\"https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/configure-safety-attributes#safety_setting_thresholds\">official guide</a> on how to use Harm Block Threshold",
            "options": [
              {
                "label": "Low and Above",
                "name": "BLOCK_LOW_AND_ABOVE"
              },
              {
                "label": "Medium and Above",
                "name": "BLOCK_MEDIUM_AND_ABOVE"
              },
              {
                "label": "None",
                "name": "BLOCK_NONE"
              },
              {
                "label": "Only High",
                "name": "BLOCK_ONLY_HIGH"
              },
              {
                "label": "Threshold Unspecified",
                "name": "HARM_BLOCK_THRESHOLD_UNSPECIFIED"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-harmBlockThreshold-multiOptions"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gemini-pro",
          "temperature": "0.5",
          "maxOutputTokens": "",
          "topP": "",
          "topK": "",
          "harmCategory": "",
          "harmBlockThreshold": ""
        },
        "outputAnchors": [
          {
            "id": "chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatGoogleGenerativeAI",
            "label": "ChatGoogleGenerativeAI",
            "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
            "type": "ChatGoogleGenerativeAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 572,
      "selected": false,
      "positionAbsolute": {
        "x": 696.2020670661773,
        "y": -231.09864382826458
      },
      "dragging": false
    },
    {
      "id": "cohereEmbeddings_0",
      "position": {
        "x": 158.3294192723738,
        "y": 751.604193296688
      },
      "type": "customNode",
      "data": {
        "id": "cohereEmbeddings_0",
        "label": "Cohere Embeddings",
        "version": 3,
        "name": "cohereEmbeddings",
        "type": "CohereEmbeddings",
        "baseClasses": [
          "CohereEmbeddings",
          "Embeddings"
        ],
        "category": "Embeddings",
        "description": "Cohere API to generate embeddings for a given text",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "cohereApi"
            ],
            "id": "cohereEmbeddings_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "embed-english-v2.0",
            "id": "cohereEmbeddings_0-input-modelName-asyncOptions"
          },
          {
            "label": "Type",
            "name": "inputType",
            "type": "options",
            "description": "Specifies the type of input passed to the model. Required for embedding models v3 and higher. <a target=\"_blank\" href=\"https://docs.cohere.com/reference/embed\">Official Docs</a>",
            "options": [
              {
                "label": "search_document",
                "name": "search_document",
                "description": "Use this to encode documents for embeddings that you store in a vector database for search use-cases"
              },
              {
                "label": "search_query",
                "name": "search_query",
                "description": "Use this when you query your vector DB to find relevant documents."
              },
              {
                "label": "classification",
                "name": "classification",
                "description": "Use this when you use the embeddings as an input to a text classifier"
              },
              {
                "label": "clustering",
                "name": "clustering",
                "description": "Use this when you want to cluster the embeddings."
              }
            ],
            "default": "search_query",
            "optional": true,
            "id": "cohereEmbeddings_0-input-inputType-options"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "modelName": "embed-english-v2.0",
          "inputType": "search_query"
        },
        "outputAnchors": [
          {
            "id": "cohereEmbeddings_0-output-cohereEmbeddings-CohereEmbeddings|Embeddings",
            "name": "cohereEmbeddings",
            "label": "CohereEmbeddings",
            "description": "Cohere API to generate embeddings for a given text",
            "type": "CohereEmbeddings | Embeddings"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 466,
      "positionAbsolute": {
        "x": 158.3294192723738,
        "y": 751.604193296688
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "tokenTextSplitter_0",
      "position": {
        "x": -222.62482542468382,
        "y": -179.50144033279503
      },
      "type": "customNode",
      "data": {
        "id": "tokenTextSplitter_0",
        "label": "Token Text Splitter",
        "version": 1,
        "name": "tokenTextSplitter",
        "type": "TokenTextSplitter",
        "baseClasses": [
          "TokenTextSplitter",
          "TextSplitter",
          "BaseDocumentTransformer",
          "Runnable"
        ],
        "category": "Text Splitters",
        "description": "Splits a raw text string by first converting the text into BPE tokens, then split these tokens into chunks and convert the tokens within a single chunk back into text.",
        "inputParams": [
          {
            "label": "Encoding Name",
            "name": "encodingName",
            "type": "options",
            "options": [
              {
                "label": "gpt2",
                "name": "gpt2"
              },
              {
                "label": "r50k_base",
                "name": "r50k_base"
              },
              {
                "label": "p50k_base",
                "name": "p50k_base"
              },
              {
                "label": "p50k_edit",
                "name": "p50k_edit"
              },
              {
                "label": "cl100k_base",
                "name": "cl100k_base"
              }
            ],
            "default": "gpt2",
            "id": "tokenTextSplitter_0-input-encodingName-options"
          },
          {
            "label": "Chunk Size",
            "name": "chunkSize",
            "type": "number",
            "default": 1000,
            "optional": true,
            "id": "tokenTextSplitter_0-input-chunkSize-number"
          },
          {
            "label": "Chunk Overlap",
            "name": "chunkOverlap",
            "type": "number",
            "optional": true,
            "id": "tokenTextSplitter_0-input-chunkOverlap-number"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "encodingName": "gpt2",
          "chunkSize": "500",
          "chunkOverlap": ""
        },
        "outputAnchors": [
          {
            "id": "tokenTextSplitter_0-output-tokenTextSplitter-TokenTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
            "name": "tokenTextSplitter",
            "label": "TokenTextSplitter",
            "description": "Splits a raw text string by first converting the text into BPE tokens, then split these tokens into chunks and convert the tokens within a single chunk back into text.",
            "type": "TokenTextSplitter | TextSplitter | BaseDocumentTransformer | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 472,
      "selected": false,
      "positionAbsolute": {
        "x": -222.62482542468382,
        "y": -179.50144033279503
      },
      "dragging": false
    },
    {
      "id": "faiss_0",
      "position": {
        "x": 598.6860067799137,
        "y": 397.13213359910196
      },
      "type": "customNode",
      "data": {
        "id": "faiss_0",
        "label": "Faiss",
        "version": 1,
        "name": "faiss",
        "type": "Faiss",
        "baseClasses": [
          "Faiss",
          "VectorStoreRetriever",
          "BaseRetriever"
        ],
        "category": "Vector Stores",
        "description": "Upsert embedded data and perform similarity search upon query using Faiss library from Meta",
        "inputParams": [
          {
            "label": "Base Path to load",
            "name": "basePath",
            "description": "Path to load faiss.index file",
            "placeholder": "C:\\Users\\User\\Desktop",
            "type": "string",
            "id": "faiss_0-input-basePath-string"
          },
          {
            "label": "Top K",
            "name": "topK",
            "description": "Number of top results to fetch. Default to 4",
            "placeholder": "4",
            "type": "number",
            "additionalParams": true,
            "optional": true,
            "id": "faiss_0-input-topK-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Document",
            "name": "document",
            "type": "Document",
            "list": true,
            "optional": true,
            "id": "faiss_0-input-document-Document"
          },
          {
            "label": "Embeddings",
            "name": "embeddings",
            "type": "Embeddings",
            "id": "faiss_0-input-embeddings-Embeddings"
          }
        ],
        "inputs": {
          "document": [
            "{{csvFile_0.data.instance}}"
          ],
          "embeddings": "{{cohereEmbeddings_0.data.instance}}",
          "basePath": "C:\\Users\\Aryan Gupta\\OneDrive\\Desktop\\RAGnarok",
          "topK": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "faiss_0-output-retriever-Faiss|VectorStoreRetriever|BaseRetriever",
                "name": "retriever",
                "label": "Faiss Retriever",
                "description": "",
                "type": "Faiss | VectorStoreRetriever | BaseRetriever"
              },
              {
                "id": "faiss_0-output-vectorStore-Faiss|SaveableVectorStore|VectorStore",
                "name": "vectorStore",
                "label": "Faiss Vector Store",
                "description": "",
                "type": "Faiss | SaveableVectorStore | VectorStore"
              }
            ],
            "default": "retriever"
          }
        ],
        "outputs": {
          "output": "retriever"
        },
        "selected": false
      },
      "width": 300,
      "height": 458,
      "selected": false,
      "positionAbsolute": {
        "x": 598.6860067799137,
        "y": 397.13213359910196
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "bufferMemory_0",
      "sourceHandle": "bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
      "target": "conversationalRetrievalQAChain_0",
      "targetHandle": "conversationalRetrievalQAChain_0-input-memory-BaseMemory",
      "type": "buttonedge",
      "id": "bufferMemory_0-bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-memory-BaseMemory"
    },
    {
      "source": "chatGoogleGenerativeAI_0",
      "sourceHandle": "chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "conversationalRetrievalQAChain_0",
      "targetHandle": "conversationalRetrievalQAChain_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatGoogleGenerativeAI_0-chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-model-BaseChatModel"
    },
    {
      "source": "csvFile_0",
      "sourceHandle": "csvFile_0-output-csvFile-Document",
      "target": "faiss_0",
      "targetHandle": "faiss_0-input-document-Document",
      "type": "buttonedge",
      "id": "csvFile_0-csvFile_0-output-csvFile-Document-faiss_0-faiss_0-input-document-Document"
    },
    {
      "source": "cohereEmbeddings_0",
      "sourceHandle": "cohereEmbeddings_0-output-cohereEmbeddings-CohereEmbeddings|Embeddings",
      "target": "faiss_0",
      "targetHandle": "faiss_0-input-embeddings-Embeddings",
      "type": "buttonedge",
      "id": "cohereEmbeddings_0-cohereEmbeddings_0-output-cohereEmbeddings-CohereEmbeddings|Embeddings-faiss_0-faiss_0-input-embeddings-Embeddings"
    },
    {
      "source": "faiss_0",
      "sourceHandle": "faiss_0-output-retriever-Faiss|VectorStoreRetriever|BaseRetriever",
      "target": "conversationalRetrievalQAChain_0",
      "targetHandle": "conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever",
      "type": "buttonedge",
      "id": "faiss_0-faiss_0-output-retriever-Faiss|VectorStoreRetriever|BaseRetriever-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
    },
    {
      "source": "recursiveCharacterTextSplitter_0",
      "sourceHandle": "recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
      "target": "csvFile_0",
      "targetHandle": "csvFile_0-input-textSplitter-TextSplitter",
      "type": "buttonedge",
      "id": "recursiveCharacterTextSplitter_0-recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable-csvFile_0-csvFile_0-input-textSplitter-TextSplitter"
    }
  ]
}